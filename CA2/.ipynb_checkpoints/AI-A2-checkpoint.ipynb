{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Zero:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install librosa numpy soundfile matplotlib noisereduce scipy\n",
    "!pip install hmmlearn colorama collections scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce as nr\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from hmmlearn import hmm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_recordings = 'recordings'\n",
    "preprocessed_recordings = 'preprocessed_recordings'\n",
    "mfcc_features = 'mfcc_features'\n",
    "\n",
    "TARGET_SAMPLING_RATE = 16000\n",
    "\n",
    "N_MFCC = 13\n",
    "N_TIME_MFCC = 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(input_path, output_path, target_sampling_rate = TARGET_SAMPLING_RATE):\n",
    "    # Load the audio file\n",
    "    audio, sampling_rate = librosa.load(input_path, sr = target_sampling_rate)\n",
    "\n",
    "    # Noise reduction\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio, sr = sampling_rate)\n",
    "\n",
    "    # Silence removal\n",
    "    non_silent_audio, _ = librosa.effects.trim(audio)\n",
    "\n",
    "    # Normalize the audio to a standard volume level\n",
    "    normalized_audio = librosa.util.normalize(non_silent_audio)\n",
    "\n",
    "    # Save the processed audio file\n",
    "    sf.write(output_path, normalized_audio, target_sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all_audio(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            preprocess_audio(file_path, output_path)\n",
    "            #print(f\"Processed {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess_all_audio(initial_recordings, preprocessed_recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_mfcc(mfcc_feature, n_time_mfcc = N_TIME_MFCC):\n",
    "    temp = np.tile(mfcc_feature, (1 ,int(np.ceil(n_time_mfcc / mfcc_feature.shape[1])) ))\n",
    "    padded_mfcc_features= temp[:,:n_time_mfcc]\n",
    "    return padded_mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_path, target_sampling_rate = TARGET_SAMPLING_RATE, n_mfcc = N_MFCC, n_time_mfcc = N_TIME_MFCC):\n",
    "    audio, _ = librosa.load(file_path)\n",
    "    mfcc_feature = librosa.feature.mfcc(y = audio, sr = target_sampling_rate, n_mfcc = n_mfcc)\n",
    "    mfcc_feature = pad_mfcc(mfcc_feature, n_time_mfcc)\n",
    "    return mfcc_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_all_files(recordings_folder, mfcc_folder):\n",
    "    if not os.path.exists(mfcc_folder):\n",
    "        os.makedirs(mfcc_folder)\n",
    "\n",
    "    for file_name in os.listdir(recordings_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(recordings_folder, file_name)\n",
    "            mfcc_feature = extract_mfcc(file_path)\n",
    "            # Save mfcc_feature as file\n",
    "            output_file_path = os.path.join(mfcc_folder, file_name.replace('.wav', '.npy'))\n",
    "            np.save(output_file_path, mfcc_feature)\n",
    "            print(f\"MFCC features extracted and saved for {file_name} , shape = {mfcc_feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_folder = 'preprocessed_recordings'\n",
    "output_folder = 'mfcc_features'\n",
    "extract_features_for_all_files(preprocess_all_audio, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mfcc_heatmaps(mfcc_dict):\n",
    "    for file_name, mfcc in mfcc_dict.items():\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.title(f'MFCC Heatmap for {file_name}')\n",
    "        librosa.display.specshow(mfcc, x_axis='time')\n",
    "        plt.yticks(range(0, 13))\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mfcc_folder = 'mfcc_features'\n",
    "index_of_interest = 0\n",
    "\n",
    "files_with_index_0 = [f for f in os.listdir(mfcc_folder) if f.endswith('.npy') and f.split('_')[-1].replace('.npy', '') == str(index_of_interest)]\n",
    "\n",
    "mfcc_features0 = {file: np.load(os.path.join(mfcc_folder, file)) for file in files_with_index_0}\n",
    "plot_mfcc_heatmaps(mfcc_features0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(mfcc_folder, m):\n",
    "    train_features, test_features = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "\n",
    "    split_index = m // 5\n",
    "    for file_name in os.listdir(mfcc_folder):\n",
    "        digit_label, speaker_name, index_str =  file_name[:-4].split('_')\n",
    "        index = int(index_str)\n",
    "        file_path = os.path.join(mfcc_folder, file_name)\n",
    "        file_path = os.path.join(mfcc_folder, file_name)\n",
    "        mfcc = np.load(file_path)\n",
    "\n",
    "        if index < split_index:\n",
    "            train_features.append(mfcc.T)\n",
    "            train_labels.append(file_name)\n",
    "        else:\n",
    "            test_features.append(mfcc.T)\n",
    "            test_labels.append(file_name)\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 50\n",
    "mfcc_folder = 'mfcc_features'\n",
    "train_features, train_labels, test_features, test_labels = prepare_data(mfcc_folder, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Three: Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract just the digit from the filename\n",
    "def extract_digit(label):\n",
    "    digit_label = label.split('_')[0]  # Extracting digit from the filename\n",
    "    return digit_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize training data by digit\n",
    "training_data_by_digit = defaultdict(list)\n",
    "for mfcc, label in zip(train_features, train_labels):\n",
    "    digit = extract_digit(label)\n",
    "    training_data_by_digit[digit].append(mfcc)\n",
    "\n",
    "# Similar for testing data\n",
    "# testing_data_by_digit = defaultdict(list)\n",
    "# for mfcc, label in zip(test_features, test_labels):\n",
    "#     digit = extract_digit(label)\n",
    "#     testing_data_by_digit[digit].append(mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HMM parameters\n",
    "n_components = 30\n",
    "hmm_models_digit = {}\n",
    "\n",
    "for digit, data in training_data_by_digit.items():\n",
    "    # Combine the sequences for this digit and find lengths for fitting\n",
    "    lengths = [len(sequence) for sequence in data]\n",
    "    X = np.concatenate(data)\n",
    "\n",
    "    # Define and train the HMM\n",
    "    model = hmm.GaussianHMM(n_components=n_components)\n",
    "    model.fit(X, lengths)\n",
    "    hmm_models_digit[digit] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare true labels for accuracy calculation\n",
    "test_true_digits = [extract_digit(label) for label in test_labels]\n",
    "\n",
    "# Predictions\n",
    "test_predictions_digits = []\n",
    "\n",
    "for mfcc in test_features:\n",
    "    best_score, best_digit = float(\"-inf\"), None\n",
    "    for digit, model in hmm_models_digit.items():\n",
    "        score = model.score(mfcc)\n",
    "        if score > best_score:\n",
    "            best_score, best_digit = score, digit\n",
    "    test_predictions_digits.append(best_digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(test_predictions_digits)):\n",
    "    if test_true_digits[i] != test_predictions_digits[i]:\n",
    "        print(Fore.RED + f\"\\033[1m{test_true_digits[i], test_predictions_digits[i]}\\033[0m\"+ Style.RESET_ALL)\n",
    "    else:\n",
    "        print(Fore.BLUE  + f\"{test_true_digits[i], test_predictions_digits[i]}\"+ Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_true_digits, test_predictions_digits)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract just the digit from the filename\n",
    "def extract_speaker(label):\n",
    "    speaker_label = label.split('_')[1]\n",
    "    return speaker_label\n",
    "\n",
    "# Organize training data by digit\n",
    "training_data_by_speaker = defaultdict(list)\n",
    "for mfcc, label in zip(train_features, train_labels):\n",
    "    speaker = extract_speaker(label)\n",
    "    training_data_by_speaker[speaker].append(mfcc)\n",
    "\n",
    "# Similar for testing data (might be used later)\n",
    "# testing_data_by_speaker = defaultdict(list)\n",
    "# for mfcc, label in zip(test_features, test_labels):\n",
    "#     speaker = extract_speaker(label)\n",
    "#     testing_data_by_speaker[speaker].append(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HMM parameters\n",
    "n_components = 30\n",
    "hmm_models_speaker = {}\n",
    "\n",
    "for speaker, data in training_data_by_speaker.items():\n",
    "    # Combine the sequences for this digit and find lengths for fitting\n",
    "    lengths = [len(sequence) for sequence in data]\n",
    "    X = np.concatenate(data)\n",
    "\n",
    "    # Define and train the HMM\n",
    "    model = hmm.GaussianHMM(n_components=n_components)\n",
    "    model.fit(X, lengths)\n",
    "    hmm_models_speaker[speaker] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare true labels for accuracy calculation\n",
    "test_true_speakers = [extract_speaker(label) for label in test_labels]\n",
    "\n",
    "# Predictions\n",
    "test_predictions_speakers = []\n",
    "\n",
    "for mfcc in test_features:\n",
    "    best_score, best_speaker = float(\"-inf\"), None\n",
    "    for speaker, model in hmm_models_speaker.items():\n",
    "        score = model.score(mfcc)\n",
    "        if score > best_score:\n",
    "            best_score, best_speaker = score, speaker\n",
    "    test_predictions_speakers.append(best_speaker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "   for i in range(len(test_predictions_speakers)):\n",
    "    if test_true_speakers[i] != test_predictions_speakers[i]:\n",
    "        print(Fore.RED + f\"\\033[1m{test_true_speakers[i], test_predictions_speakers[i]}\\033[0m\"+ Style.RESET_ALL)\n",
    "    else:\n",
    "        print(Fore.BLUE  + f\"{test_true_speakers[i], test_predictions_speakers[i]}\"+ Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_true_speakers, test_predictions_speakers)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define HMM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, num_hidden_states):\n",
    "        self.num_hidden_states = num_hidden_states\n",
    "        self.rand_state = np.random.RandomState(1)\n",
    "\n",
    "        self.initial_prob = self._normalize(self.rand_state.rand(self.num_hidden_states, 1))\n",
    "        self.transition_matrix = self._stochasticize(self.rand_state.rand(self.num_hidden_states, self.num_hidden_states))\n",
    "\n",
    "        self.mean = None\n",
    "        self.covariances = None\n",
    "        self.num_dimensions = None\n",
    "\n",
    "    def _forward(self, observation_matrix):\n",
    "        log_likelihood = 0.\n",
    "        T = observation_matrix.shape[1]\n",
    "        alpha = np.zeros(observation_matrix.shape)\n",
    "\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                alpha[:, t] = observation_matrix[:, t] * self.initial_prob.flatten() * observation_matrix[:, t]\n",
    "                ## TODO: Forward algorithm for the first time step\n",
    "            else:\n",
    "                alpha[:, t] = observation_matrix[:, t] * np.dot(alpha[:, t-1], self.transition_matrix)\n",
    "                ## TODO: Forward algorithm for the next time steps\n",
    "\n",
    "            alpha_sum = np.sum(alpha[:, t])\n",
    "            alpha[:, t] /= alpha_sum\n",
    "            log_likelihood += np.log(alpha_sum)\n",
    "\n",
    "        return log_likelihood, alpha\n",
    "\n",
    "    def _backward(self, observation_matrix):\n",
    "        T = observation_matrix.shape[1]\n",
    "        beta = np.zeros(observation_matrix.shape)\n",
    "\n",
    "        beta[:, -1] = np.ones(observation_matrix.shape[0])\n",
    "\n",
    "        for t in range(T - 1)[::-1]:\n",
    "            beta[:, t] = np.dot(self.transition_matrix.T,(observation_matrix[:, t+1] * beta[:, t+1]))\n",
    "            ## TODO: Backward algorithm for the time steps of the HMM\n",
    "            beta[:, t] /= np.sum(beta[:, t])\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def _state_likelihood(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = np.zeros((self.num_hidden_states, obs.shape[1]))\n",
    "\n",
    "        for s in range(self.num_hidden_states):\n",
    "            mean_T =self.mean[:, s].T\n",
    "            covariance_T = self.covariances[:, :, s].T\n",
    "            obs_T = obs.T\n",
    "            B[s, :] = multivariate_normal.pdf(x = obs_T, mean=mean_T, cov=covariance_T)\n",
    "            ## TODO: Compute the likelihood of observations with multivariate normal pdf\n",
    "        return B\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x)\n",
    "\n",
    "    def _stochasticize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x, axis=0)\n",
    "\n",
    "    def _em_init(self, obs):\n",
    "        if self.num_dimensions is None:\n",
    "            self.num_dimensions = obs.shape[0]\n",
    "        if self.mean is None:\n",
    "            subset = self.rand_state.choice(\n",
    "                np.arange(self.num_dimensions), size=self.num_hidden_states, replace=False)\n",
    "            self.mean = obs[:, subset]\n",
    "        if self.covariances is None:\n",
    "            self.covariances = np.zeros(\n",
    "                (self.num_dimensions, self.num_dimensions, self.num_hidden_states))\n",
    "            self.covariances += np.diag(np.diag(np.cov(obs)))[:, :, None]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _em_step(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        T = obs.shape[1]\n",
    "\n",
    "        B = self._state_likelihood(obs) ## TODO\n",
    "\n",
    "        log_likelihood, alpha = self._forward(B) ## TODO\n",
    "        beta = self._backward(B) ## TODO\n",
    "\n",
    "        xi_sum = np.zeros((self.num_hidden_states, self.num_hidden_states))\n",
    "        gamma = np.zeros((self.num_hidden_states, T))\n",
    "\n",
    "        for t in range(T - 1):\n",
    "            partial_sum = self.transition_matrix.T * np.inner(np.outer(B[:, t + 1],beta[:, t + 1]), alpha[:, t]) ## TODO\n",
    "            xi_sum += self._normalize(partial_sum)\n",
    "            partial_g = alpha[:, t] * beta[:, t] ## TODO\n",
    "            gamma[:, t] = self._normalize(partial_g)\n",
    "        partial_g = alpha[:, -1] * beta[:, -1] ## TODO\n",
    "        gamma[:, -1] = self._normalize(partial_g)\n",
    "\n",
    "        expected_prior = gamma[:, 0] ## TODO\n",
    "        expected_transition = self._stochasticize(xi_sum)\n",
    "\n",
    "        expected_covariances = np.zeros(\n",
    "            (self.num_dimensions, self.num_dimensions, self.num_hidden_states))\n",
    "        expected_covariances += .01 * np.eye(self.num_dimensions)[:, :, None]\n",
    "\n",
    "        gamma_state_sum = np.sum(gamma, axis=1)\n",
    "        gamma_state_sum = gamma_state_sum + (gamma_state_sum == 0)\n",
    "\n",
    "        expected_mean = np.zeros((self.num_dimensions, self.num_hidden_states))\n",
    "        for s in range(self.num_hidden_states):\n",
    "            gamma_obs = obs * gamma[s, :]\n",
    "            expected_mean[:, s] = np.sum(\n",
    "                gamma_obs, axis=1) / gamma_state_sum[s]\n",
    "\n",
    "        self.initial_prob = expected_prior\n",
    "        self.mean = expected_mean\n",
    "        self.transition_matrix = expected_transition\n",
    "\n",
    "        return log_likelihood\n",
    "\n",
    "    def train(self, obs, num_iterations=1):\n",
    "        for i in range(num_iterations):\n",
    "\n",
    "\n",
    "            self._em_init(obs)\n",
    "            self._em_step(obs)\n",
    "        return self\n",
    "\n",
    "    def score(self, obs):\n",
    "        B = self._state_likelihood(obs)\n",
    "        log_likelihood, _ = self._forward(B)\n",
    "        return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize HMM parameters\n",
    "num_hidden_states = 13\n",
    "hmm_models_digit_2 = {}\n",
    "i = 0\n",
    "for digit, data in training_data_by_digit.items():\n",
    "    model = HMM(num_hidden_states)\n",
    "    X = np.concatenate(data)\n",
    "    model.train(X.T, 1)\n",
    "    hmm_models_digit_2[digit] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare true labels for accuracy calculation\n",
    "test_true_digits = [extract_digit(label) for label in test_labels]\n",
    "\n",
    "# Predictions\n",
    "test_predictions_digits = []\n",
    "\n",
    "for mfcc in test_features:\n",
    "    best_score, best_digit = float(\"-inf\"), None\n",
    "    for digit, model in hmm_models_digit_2.items():\n",
    "        score = model.score(mfcc.T)\n",
    "        if score > best_score:\n",
    "            best_score, best_digit = score, digit\n",
    "    test_predictions_digits.append(best_digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(test_predictions_digits)):\n",
    "    if test_true_digits[i] != test_predictions_digits[i]:\n",
    "        print(Fore.RED + f\"\\033[1m{test_true_digits[i], test_predictions_digits[i]}\\033[0m\"+ Style.RESET_ALL)\n",
    "    else:\n",
    "        print(Fore.BLUE  + f\"{test_true_digits[i], test_predictions_digits[i]}\"+ Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_true_digits, test_predictions_digits)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " hmm_models = []\n",
    "\n",
    "## TODO\n",
    "# Iterate through each unique digti in the training data\n",
    "# extract features from the audio files, and train a HMM for\n",
    "# each genre, storing the trained models in the hmm_models list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# In this section, iterate through the audio files, extract\n",
    "# features, and use the trained HMMs to predict the genre\n",
    "# for each audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Four: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
