{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fatemeh Mohammadi - 810199489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Zero: Import Libraries & Set Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install librosa numpy soundfile matplotlib noisereduce scipy\n",
    "!pip install hmmlearn colorama collections scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce as nr\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from hmmlearn import hmm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style\n",
    "from collections import defaultdict\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_recordings_folder = 'recordings'\n",
    "preprocessed_recordings_folder = 'preprocessed_recordings'\n",
    "mfcc_features_folder = 'mfcc_features'\n",
    "heatmaps_folder = \"heatmaps\"\n",
    "\n",
    "DIGITS = []\n",
    "SPEAKERS = []\n",
    "\n",
    "TARGET_SAMPLING_RATE = 16000\n",
    "\n",
    "N_MFCC = 13\n",
    "N_FRAME_MFCC = 30\n",
    "\n",
    "NUM_REPEATED_RECORDING = 50\n",
    "\n",
    "TRAIN_PERCENT = 0.3\n",
    "TEST_PERCENT = 1 - TRAIN_PERCENT\n",
    "\n",
    "NUM_STATE = 13\n",
    "NUM_ITERATION = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One: Preprocessing & Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(input_path, output_path, target_sampling_rate = TARGET_SAMPLING_RATE):\n",
    "    # Load the audio file\n",
    "    audio, sampling_rate = librosa.load(input_path, sr = target_sampling_rate)\n",
    "\n",
    "    # Noise reduction\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio, sr = sampling_rate)\n",
    "\n",
    "    # Silence removal\n",
    "    non_silent_audio, _ = librosa.effects.trim(audio)\n",
    "\n",
    "    # Normalize the audio to a standard volume level\n",
    "    normalized_audio = librosa.util.normalize(non_silent_audio)\n",
    "\n",
    "    # Save the processed audio file\n",
    "    sf.write(output_path, normalized_audio, target_sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all_audio(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            preprocess_audio(file_path, output_path)\n",
    "            #print(f\"Processed {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess_all_audio(initial_recordings_folder, preprocessed_recordings_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_mfcc(raw_mfcc, n_frame_mfcc = N_FRAME_MFCC):\n",
    "    temp = np.tile(raw_mfcc, (1 ,int(np.ceil(n_frame_mfcc / raw_mfcc.shape[1])) ))\n",
    "    padded_mfcc_features= temp[:,:n_frame_mfcc]\n",
    "    return padded_mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_path, target_sampling_rate = TARGET_SAMPLING_RATE, n_mfcc = N_MFCC, n_frame_mfcc = N_FRAME_MFCC):\n",
    "    audio, _ = librosa.load(file_path)\n",
    "    raw_mfcc = librosa.feature.mfcc(y = audio, sr = target_sampling_rate, n_mfcc = n_mfcc)\n",
    "    mfcc = pad_mfcc(raw_mfcc, n_frame_mfcc)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_all_files(recordings_folder, mfcc_folder):\n",
    "    if not os.path.exists(mfcc_folder):\n",
    "        os.makedirs(mfcc_folder)\n",
    "\n",
    "    for file_name in os.listdir(recordings_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(recordings_folder, file_name)\n",
    "            mfcc_feature = extract_mfcc(file_path)\n",
    "            # Save mfcc_feature as file\n",
    "            output_file_path = os.path.join(mfcc_folder, file_name.replace('.wav', '.npy'))\n",
    "            np.save(output_file_path, mfcc_feature)\n",
    "            #print(f\"MFCC features extracted and saved for {file_name} , shape = {mfcc_feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_features_for_all_files(preprocessed_recordings_folder, mfcc_features_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mfcc_files= [f for f in os.listdir(mfcc_features_folder) if f.endswith('.npy')]\n",
    "mfcc_features = {file: np.load(os.path.join(mfcc_features_folder, file)) for file in mfcc_files}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Heat Map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mfcc_heatmaps(mfccs, n_mfcc = N_MFCC):\n",
    "    for file_name, mfcc in mfccs.items():\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.title(f'MFCC Heatmap for {file_name}')\n",
    "        librosa.display.specshow(mfcc, x_axis='time')\n",
    "        plt.yticks(range(0, n_mfcc))\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_with_index_0 = [f for f in os.listdir(mfcc_features_folder) if f.endswith('_0.npy')]\n",
    "mfcc_features_index_0 = {file: np.load(os.path.join(mfcc_features_folder, file)) for file in files_with_index_0}\n",
    "plot_mfcc_heatmaps(mfcc_features_index_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_mfcc_heatmaps(mfccs, folder_name, n_mfcc = N_MFCC):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    for file_name, mfcc in mfccs.items():\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.title(f'MFCC Heatmap for {file_name}')\n",
    "        librosa.display.specshow(mfcc, x_axis='time')\n",
    "        plt.yticks(range(0, n_mfcc))\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.tight_layout()\n",
    "        full_path = os.path.join(folder_name, file_name.replace('.npy', ''))\n",
    "        plt.savefig(full_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_plot_mfcc_heatmaps(mfcc_features, heatmaps_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two: Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(mfccs, num_repeated_recoding = NUM_REPEATED_RECORDING):\n",
    "    train_features, test_features = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "\n",
    "    split_index = num_repeated_recoding * TRAIN_PERCENT\n",
    "    for file_name, mfcc in mfccs.items():\n",
    "        digit_label, speaker_name, index_str =  file_name[:-4].split('_')\n",
    "        index = int(index_str)\n",
    "        if index < split_index:\n",
    "            train_features.append(mfcc.T)\n",
    "            train_labels.append(file_name)\n",
    "        else:\n",
    "            test_features.append(mfcc.T)\n",
    "            test_labels.append(file_name)\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels = prepare_data(mfcc_features, NUM_REPEATED_RECORDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Three: Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_detailed_report(arr1, arr2):\n",
    "    t = 0\n",
    "    f = 0\n",
    "    for i in range(len(arr1)):\n",
    "        if arr1[i] != arr2[i]:\n",
    "            f = f + 1\n",
    "        else:\n",
    "            t = t + 1\n",
    "    print(f\"num_true = {t}, num_false = {f}\")\n",
    "    for i in range(len(arr1)):\n",
    "        print(i)\n",
    "        if arr1[i] != arr2[i]:\n",
    "            print(Fore.RED + f\"\\033[1m{arr1[i], arr2[i]}\\033[0m\"+ Style.RESET_ALL)\n",
    "        else:\n",
    "            print(Fore.BLUE  + f\"{arr1[i], arr2[i]}\"+ Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_digit(label):\n",
    "    digit_label = label.split('_')[0]\n",
    "    return digit_label\n",
    "\n",
    "def extract_speaker(label):\n",
    "    speaker_label = label.split('_')[1]\n",
    "    return speaker_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize training data by digit\n",
    "training_data_by_digit = defaultdict(list)\n",
    "for mfcc, label in zip(train_features, train_labels):\n",
    "    digit = extract_digit(label)\n",
    "    training_data_by_digit[digit].append(mfcc)\n",
    "\n",
    "# Organize training data by speaker\n",
    "training_data_by_speaker = defaultdict(list)\n",
    "for mfcc, label in zip(train_features, train_labels):\n",
    "    speaker = extract_speaker(label)\n",
    "    training_data_by_speaker[speaker].append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true_digits = [extract_digit(label) for label in test_labels]\n",
    "test_true_speakers = [extract_speaker(label) for label in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_models_digit_1 = {}\n",
    "\n",
    "for digit, data in training_data_by_digit.items():\n",
    "    lengths = [len(sequence) for sequence in data]\n",
    "    X = np.concatenate(data)\n",
    "    model = hmm.GaussianHMM(n_components = NUM_STATE)\n",
    "    model.fit(X, lengths)\n",
    "    hmm_models_digit_1[digit] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_digits_1 = []\n",
    "\n",
    "for mfcc in test_features:\n",
    "    best_score, best_digit = float(\"-inf\"), None\n",
    "    for digit, model in hmm_models_digit_1.items():\n",
    "        score = model.score(mfcc)\n",
    "        if score > best_score:\n",
    "            best_score, best_digit = score, digit\n",
    "    test_predictions_digits_1.append(best_digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_detailed_report(test_true_digits, test_predictions_digits_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_models_speaker_1 = {}\n",
    "\n",
    "for speaker, data in training_data_by_speaker.items():\n",
    "    lengths = [len(sequence) for sequence in data]\n",
    "    X = np.concatenate(data)\n",
    "    model = hmm.GaussianHMM(n_components = NUM_STATE)\n",
    "    model.fit(X, lengths)\n",
    "    hmm_models_speaker_1[speaker] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_speakers_1 = []\n",
    "\n",
    "for mfcc in test_features:\n",
    "    best_score, best_speaker = float(\"-inf\"), None\n",
    "    for speaker, model in hmm_models_speaker_1.items():\n",
    "        score = model.score(mfcc)\n",
    "        if score > best_score:\n",
    "            best_score, best_speaker = score, speaker\n",
    "    test_predictions_speakers_1.append(best_speaker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_detailed_report(test_true_speakers, test_predictions_speakers_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define HMM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, num_hidden_states):\n",
    "        self.num_hidden_states = num_hidden_states\n",
    "        self.rand_state = np.random.RandomState(1)\n",
    "\n",
    "        self.initial_prob = self._normalize(self.rand_state.rand(self.num_hidden_states, 1))\n",
    "        self.transition_matrix = self._stochasticize(self.rand_state.rand(self.num_hidden_states, self.num_hidden_states))\n",
    "\n",
    "        self.mean = None\n",
    "        self.covariances = None\n",
    "        self.num_dimensions = None\n",
    "\n",
    "    def _forward(self, observation_matrix):\n",
    "        log_likelihood = 0.\n",
    "        T = observation_matrix.shape[1]\n",
    "        alpha = np.zeros(observation_matrix.shape)\n",
    "\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                alpha[:, t] = observation_matrix[:, t] * self.initial_prob.flatten() \n",
    "                ## TODO: Forward algorithm for the first time step\n",
    "            else:\n",
    "                alpha[:, t] = observation_matrix[:, t] * np.dot(alpha[:, t-1], self.transition_matrix)\n",
    "                ## TODO: Forward algorithm for the next time steps\n",
    "\n",
    "            alpha_sum = np.sum(alpha[:, t])\n",
    "            alpha[:, t] /= alpha_sum\n",
    "            log_likelihood += np.log(alpha_sum)\n",
    "\n",
    "        return log_likelihood, alpha\n",
    "\n",
    "    def _backward(self, observation_matrix):\n",
    "        T = observation_matrix.shape[1]\n",
    "        beta = np.zeros(observation_matrix.shape)\n",
    "\n",
    "        beta[:, -1] = np.ones(observation_matrix.shape[0])\n",
    "\n",
    "        for t in range(T - 1)[::-1]:\n",
    "            beta[:, t] = np.dot(self.transition_matrix.T,(observation_matrix[:, t+1] * beta[:, t+1]))\n",
    "            ## TODO: Backward algorithm for the time steps of the HMM\n",
    "            beta[:, t] /= np.sum(beta[:, t])\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def _state_likelihood(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = np.zeros((self.num_hidden_states, obs.shape[1]))\n",
    "\n",
    "        for s in range(self.num_hidden_states):\n",
    "            mean_T =self.mean[:, s].T\n",
    "            covariance_T = self.covariances[:, :, s].T\n",
    "            obs_T = obs.T\n",
    "            B[s, :] = scipy.stats.multivariate_normal.pdf(x = obs_T, mean=mean_T, cov=covariance_T)\n",
    "            ## TODO: Compute the likelihood of observations with multivariate normal pdf\n",
    "        return B\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x)\n",
    "\n",
    "    def _stochasticize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x, axis=0)\n",
    "\n",
    "    def _em_init(self, obs):\n",
    "        if self.num_dimensions is None:\n",
    "            self.num_dimensions = obs.shape[0]\n",
    "        if self.mean is None:\n",
    "            subset = self.rand_state.choice(\n",
    "                np.arange(self.num_dimensions), size=self.num_hidden_states, replace=False)\n",
    "            self.mean = obs[:, subset]\n",
    "        if self.covariances is None:\n",
    "            self.covariances = np.zeros(\n",
    "                (self.num_dimensions, self.num_dimensions, self.num_hidden_states))\n",
    "            self.covariances += np.diag(np.diag(np.cov(obs)))[:, :, None]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _em_step(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        T = obs.shape[1]\n",
    "\n",
    "        B = self._state_likelihood(obs) ## TODO\n",
    "\n",
    "        log_likelihood, alpha = self._forward(B) ## TODO\n",
    "        beta = self._backward(B) ## TODO\n",
    "\n",
    "        xi_sum = np.zeros((self.num_hidden_states, self.num_hidden_states))\n",
    "        gamma = np.zeros((self.num_hidden_states, T))\n",
    "\n",
    "        for t in range(T - 1):\n",
    "            partial_sum = self.transition_matrix.T * np.inner(np.outer(B[:, t + 1],beta[:, t + 1]), alpha[:, t]) ## TODO\n",
    "            xi_sum += self._normalize(partial_sum)\n",
    "            partial_g = alpha[:, t] * beta[:, t] ## TODO\n",
    "            gamma[:, t] = self._normalize(partial_g)\n",
    "        partial_g = alpha[:, -1] * beta[:, -1] ## TODO\n",
    "        gamma[:, -1] = self._normalize(partial_g)\n",
    "\n",
    "        expected_prior = gamma[:, 0] ## TODO\n",
    "        expected_transition = self._stochasticize(xi_sum)\n",
    "\n",
    "        expected_covariances = np.zeros(\n",
    "            (self.num_dimensions, self.num_dimensions, self.num_hidden_states))\n",
    "        expected_covariances += .01 * np.eye(self.num_dimensions)[:, :, None]\n",
    "\n",
    "        gamma_state_sum = np.sum(gamma, axis=1)\n",
    "        gamma_state_sum = gamma_state_sum + (gamma_state_sum == 0)\n",
    "\n",
    "        expected_mean = np.zeros((self.num_dimensions, self.num_hidden_states))\n",
    "        for s in range(self.num_hidden_states):\n",
    "            gamma_obs = obs * gamma[s, :]\n",
    "            expected_mean[:, s] = np.sum(\n",
    "                gamma_obs, axis=1) / gamma_state_sum[s]\n",
    "\n",
    "        self.initial_prob = expected_prior\n",
    "        self.mean = expected_mean\n",
    "        self.transition_matrix = expected_transition\n",
    "\n",
    "        return log_likelihood\n",
    "\n",
    "    def train(self, obs, num_iterations=1):\n",
    "        for i in range(num_iterations):\n",
    "\n",
    "\n",
    "            self._em_init(obs)\n",
    "            self._em_step(obs)\n",
    "        return self\n",
    "\n",
    "    def score(self, obs):\n",
    "        B = self._state_likelihood(obs)\n",
    "        log_likelihood, _ = self._forward(B)\n",
    "        return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmm_models_digit_2 = {}\n",
    "\n",
    "for digit, data in training_data_by_digit.items():\n",
    "    model = HMM(num_hidden_states = NUM_STATE)\n",
    "    X = np.concatenate(data)\n",
    "    model.train(X.T, NUM_ITERATION)\n",
    "    hmm_models_digit_2[digit] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_digits_2 = []\n",
    "\n",
    "for mfcc in test_features:\n",
    "    best_score, best_digit = float(\"-inf\"), None\n",
    "    for digit, model in hmm_models_digit_2.items():\n",
    "        score = model.score(mfcc.T)\n",
    "        if score > best_score:\n",
    "            best_score, best_digit = score, digit\n",
    "    test_predictions_digits_2.append(best_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_detailed_report(test_true_digits, test_predictions_digits_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_models_speaker_2 = {}\n",
    "\n",
    "for speaker, data in training_data_by_speaker.items():\n",
    "    model = HMM(num_hidden_states = NUM_STATE)\n",
    "    X = np.concatenate(data)\n",
    "    model.train(X.T, NUM_ITERATION)\n",
    "    hmm_models_speaker_2[speaker] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_speakers_2 = []\n",
    "\n",
    "for mfcc in test_features:\n",
    "    best_score, best_speker = float(\"-inf\"), None\n",
    "    for speaker, model in hmm_models_speaker_2.items():\n",
    "        score = model.score(mfcc.T)\n",
    "        if score > best_score:\n",
    "            best_score, best_speker = score, speaker\n",
    "    test_predictions_speakers_2.append(best_speker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_detailed_report(test_true_speakers, test_predictions_speakers_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Four: Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_true, y_pred):\n",
    "    classes = sorted(set(y_true))\n",
    "    class_indices = {cls: i for i, cls in enumerate(classes)}\n",
    "    matrix = [[0 for _ in classes] for _ in classes]\n",
    "    for actual, predicted in zip(y_true, y_pred):\n",
    "        i = class_indices[actual]\n",
    "        j = class_indices[predicted]\n",
    "        matrix[i][j] += 1\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix, classes):\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(matrix, cmap=plt.cm.Spectral)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "    plt.yticks(np.arange(len(classes)), classes)\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.set_ylabel('True')\n",
    "\n",
    "    for (i, j), val in np.ndenumerate(matrix):\n",
    "        ax.text(j, i, f'{val}', ha='center', va='center', color='black')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot_confusion_matrix(true_vals, predict_vals, vals, type, part):\n",
    "    print(f\"for {part}:\")\n",
    "    cm = create_confusion_matrix(true_vals, predict_vals)\n",
    "    plot_confusion_matrix(cm, vals)\n",
    "    return np.array(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(confusion_matrix, class_index):\n",
    "    TP = confusion_matrix[class_index, class_index]\n",
    "    TN = np.sum(confusion_matrix) - np.sum(confusion_matrix[class_index, :]) - np.sum(confusion_matrix[:, class_index]) + TP\n",
    "    FP = np.sum(confusion_matrix[:, class_index]) - TP\n",
    "    FN = np.sum(confusion_matrix[class_index, :]) - TP\n",
    "    return TP, TN, FP, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(confusion_matrix, vals):\n",
    "    accs = []\n",
    "    for i in range(len(vals)):\n",
    "        TP, TN, FP, FN = calculate_metrics(confusion_matrix, i)\n",
    "        ALL = TP + TN + FP + FN\n",
    "        T = TP + TN\n",
    "        acc = T/ALL\n",
    "        accs.append(acc)\n",
    "        print(f\"  {vals[i]} : {acc* 100:.2f}\")\n",
    "    print(f\"macro avg accuracy = {sum(accs)/len(accs) * 100:.2f}%\")\n",
    "    print(\"--\" * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracies(cm_1, cm_2, vals, type):\n",
    "    print(\"accuracies for \" + type + \"-\" + \"part 1:\")\n",
    "    print_accuracy(cm_1, vals)\n",
    "    print(\"accuracies for \" + type + \"-\" + \"part 2:\")\n",
    "    print_accuracy(cm_2, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precision(confusion_matrix, vals):\n",
    "    precs = []\n",
    "    for i in range(len(vals)):\n",
    "        TP, TN, FP, FN = calculate_metrics(confusion_matrix, i)\n",
    "        precision = TP / (TP + FP)\n",
    "        precs.append(precision)\n",
    "        print(f\"  {vals[i]} : {precision* 100:.2f}\")\n",
    "    print(f\"macro avg precision = {sum(precs)/len(precs) * 100:.2f}%\")\n",
    "    print(\"--\" * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precisions(cm_1, cm_2, vals, type):\n",
    "    print(\"precision for \" + type + \"-\" + \"part 1:\")\n",
    "    print_precision(cm_1, vals)\n",
    "    print(\"precision for \" + type + \"-\" + \"part 2:\")\n",
    "    print_precision(cm_2, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recall(confusion_matrix, vals):\n",
    "    recs = []\n",
    "    for i in range(len(vals)):\n",
    "        TP, TN, FP, FN = calculate_metrics(confusion_matrix, i)\n",
    "        recall = TP / (TP + FN)\n",
    "        recs.append(recall)\n",
    "        print(f\"  {vals[i]} : {recall* 100:.2f}\")\n",
    "    print(f\"macro avg recall = {sum(recs)/len(recs) * 100:.2f}%\")\n",
    "    print(\"--\" * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recalls(cm_1, cm_2, vals, type):\n",
    "    print(\"recall for \" + type + \"-\" + \"part 1:\")\n",
    "    print_recall(cm_1, vals)\n",
    "    print(\"recall for \" + type + \"-\" + \"part 2:\")\n",
    "    print_recall(cm_2, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_f1(confusion_matrix, vals):\n",
    "    f1s = []\n",
    "    for i in range(len(vals)):\n",
    "        TP, TN, FP, FN = calculate_metrics(confusion_matrix, i)\n",
    "        p =  TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        f1 = 2 * r * p / (r + p)\n",
    "        f1s.append(f1)\n",
    "        print(f\"  {vals[i]} : {f1* 100:.2f}\")\n",
    "    print(f\"macro avg F1 score = {sum(f1s)/len(f1s) * 100:.2f}%\")\n",
    "    print(\"--\" * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_f1_scores(cm_1, cm_2, vals, type):\n",
    "    print(\"F1 score for \" + type + \"-\" + \"part 1:\")\n",
    "    print_f1(cm_1, vals)\n",
    "    print(\"F1 score for \" + type + \"-\" + \"part 2:\")\n",
    "    print_f1(cm_2, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics(confusion_matrix, vals):\n",
    "    f1s = []\n",
    "    recs = []\n",
    "    accs = []\n",
    "    precs = []\n",
    "    for i in range(len(vals)):\n",
    "        TP, TN, FP, FN = calculate_metrics(confusion_matrix, i)\n",
    "        ALL = TP + TN + FP + FN\n",
    "        T = TP + TN \n",
    "        acc = T/ALL\n",
    "        pre =  TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * recall * pre / (recall + pre)\n",
    "        f1s.append(f1 * 100)\n",
    "        recs.append(recall* 100)\n",
    "        accs.append(acc * 100)\n",
    "        precs.append(pre * 100)\n",
    "    return  accs, precs, recs, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metric_2_approch(cm_1, cm_2, vals, type):\n",
    "    accs1, precs1, recs1, f1s1 = all_metrics(cm_1, vals)\n",
    "    accs2, precs2, recs2, f1s2 = all_metrics(cm_2, vals)\n",
    "    \n",
    "    x = np.arange(len(vals))\n",
    "    width = 0.35 \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10)) \n",
    "\n",
    "    # Plotting accuracy\n",
    "    rects1 = axs[0, 0].bar(x - width/2, accs1, width, label='Accuracy - part 1')\n",
    "    rects2 = axs[0, 0].bar(x + width/2, accs2, width, label='Accuracy - part 2')\n",
    "    axs[0, 0].set_title('Accuracy Comparison')\n",
    "    axs[0, 0].set_xticks(x)\n",
    "    axs[0, 0].set_xticklabels(vals)\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    avg_acc1 = np.mean(accs1)\n",
    "    avg_acc2 = np.mean(accs2)\n",
    "    var_acc1 = np.var(accs1)\n",
    "    var_acc2 = np.var(accs2)\n",
    "    axs[0, 0].annotate(f'Avg 1: {avg_acc1:.2f}, Var 1: {var_acc1:.2f}\\nAvg 2: {avg_acc2:.2f}, Var 2: {var_acc2:.2f}', \n",
    "                       xy=(0.5, 0.95), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "    # Plotting precision\n",
    "    rects1 = axs[0, 1].bar(x - width/2, precs1, width, label='Precision - part 1')\n",
    "    rects2 = axs[0, 1].bar(x + width/2, precs2, width, label='Precision - part 2')\n",
    "    axs[0, 1].set_title('Precision Comparison')\n",
    "    axs[0, 1].set_xticks(x)\n",
    "    axs[0, 1].set_xticklabels(vals)\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    avg_prec1 = np.mean(precs1)\n",
    "    avg_prec2 = np.mean(precs2)\n",
    "    var_prec1 = np.var(precs1)\n",
    "    var_prec2 = np.var(precs2)\n",
    "    axs[0, 1].annotate(f'Avg 1: {avg_prec1:.2f}, Var 1: {var_prec1:.2f}\\nAvg 2: {avg_prec2:.2f}, Var 2: {var_prec2:.2f}', \n",
    "                       xy=(0.5, 0.95), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "    # Plotting recall\n",
    "    rects1 = axs[1, 0].bar(x - width/2, recs1, width, label='Recall - part 1')\n",
    "    rects2 = axs[1, 0].bar(x + width/2, recs2, width, label='Recall - part 2')\n",
    "    axs[1, 0].set_title('Recall Comparison')\n",
    "    axs[1, 0].set_xticks(x)\n",
    "    axs[1, 0].set_xticklabels(vals)\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    avg_recall1 = np.mean(recs1)\n",
    "    avg_recall2 = np.mean(recs2)\n",
    "    var_recall1 = np.var(recs1)\n",
    "    var_recall2 = np.var(recs2)\n",
    "    axs[1, 0].annotate(f'Avg 1: {avg_recall1:.2f}, Var 1: {var_recall1:.2f}\\nAvg 2: {avg_recall2:.2f}, Var 2: {var_recall2:.2f}', \n",
    "                       xy=(0.5, 0.95), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "    # Plotting F1 score\n",
    "    rects1 = axs[1, 1].bar(x - width/2, f1s1, width, label='F1 Score - part 1')\n",
    "    rects2 = axs[1, 1].bar(x + width/2, f1s2, width, label='F1 Score - part 2')\n",
    "    axs[1, 1].set_title('F1 Score Comparison')\n",
    "    axs[1, 1].set_xticks(x)\n",
    "    axs[1, 1].set_xticklabels(vals)\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    avg_f1_1 = np.mean(f1s1)\n",
    "    avg_f1_2 = np.mean(f1s2)\n",
    "    var_f1_1 = np.var(f1s1)\n",
    "    var_f1_2 = np.var(f1s2)\n",
    "    axs[1, 1].annotate(f'Avg 1: {avg_f1_1:.2f}, Var 1: {var_f1_1:.2f}\\nAvg 2: {avg_f1_2:.2f}, Var 2: {var_f1_2:.2f}', \n",
    "                       xy=(0.5, 0.95), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "    plt.xticks(rotation=45, ha='right') \n",
    "    plt.tight_layout() \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGITS = list(set(test_true_digits))\n",
    "DIGITS = sorted(DIGITS)\n",
    "print(DIGITS)\n",
    "cm_d_1 = create_plot_confusion_matrix(test_true_digits,test_predictions_digits_1, DIGITS, \"digits\", \"part 1\")\n",
    "cm_d_2 = create_plot_confusion_matrix(test_true_digits,test_predictions_digits_2, DIGITS, \"digits\", \"part 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracies(cm_d_1, cm_d_2, DIGITS, \"digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_precisions(cm_d_1, cm_d_2, DIGITS, \"digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_recalls(cm_d_1, cm_d_2, DIGITS, \"digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_f1_scores(cm_d_1, cm_d_2, DIGITS, \"digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metric_2_approch(cm_d_1, cm_d_2, DIGITS, \"digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKERS = list(set(test_true_speakers))\n",
    "SPEAKERS = sorted(SPEAKERS)\n",
    "print(SPEAKERS)\n",
    "cm_s_1 = create_plot_confusion_matrix(test_true_speakers,test_predictions_speakers_1, SPEAKERS, \"speakers\", \"part 1\")\n",
    "cm_s_2 = create_plot_confusion_matrix(test_true_speakers,test_predictions_speakers_2, SPEAKERS, \"speakers\", \"part 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracies(cm_s_1, cm_s_2, SPEAKERS, \"speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_precisions(cm_s_1, cm_s_2, SPEAKERS, \"speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_recalls(cm_s_1, cm_s_2, SPEAKERS, \"speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_f1_scores(cm_s_1, cm_s_2, SPEAKERS, \"speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metric_2_approch(cm_s_1, cm_s_2, SPEAKERS, \"speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
