{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: setuptools in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (69.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: librosa in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (0.10.1)\n",
      "Requirement already satisfied: noisereduce in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (3.0.2)\n",
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.3.2-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (4.10.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from noisereduce) (3.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from noisereduce) (4.66.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.0->librosa) (4.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.0->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.20.0->librosa) (3.3.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->noisereduce) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->noisereduce) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->noisereduce) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->noisereduce) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->noisereduce) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->noisereduce) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->noisereduce) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->noisereduce) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\afraa\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
      "Downloading hmmlearn-0.3.2-cp312-cp312-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.7 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/124.7 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 30.7/124.7 kB 445.2 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 41.0/124.7 kB 281.8 kB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 92.2/124.7 kB 479.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 112.6/124.7 kB 469.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 124.7/124.7 kB 431.8 kB/s eta 0:00:00\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade setuptools\n",
    "!pip install librosa noisereduce hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hmmlearn import hmm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path, output_path, target_sampling_rate=16000):\n",
    "    # Load the audio file\n",
    "    audio, sampling_rate = librosa.load(file_path, sr=target_sampling_rate)\n",
    "\n",
    "    # Noise reduction\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio, sr=sampling_rate)\n",
    "\n",
    "    # Silence removal\n",
    "    non_silent_audio, _ = librosa.effects.trim(reduced_noise_audio, top_db=20) # top_db: threshold for silence in dB\n",
    "\n",
    "    # Normalize the audio to a standard volume level\n",
    "    normalized_audio = librosa.util.normalize(non_silent_audio)\n",
    "\n",
    "    # Save the processed audio file\n",
    "    sf.write(output_path, normalized_audio, target_sampling_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'recordings/'\n",
    "preprocessed_directory = 'preprocessed_recordings/'\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.wav'):  # Assuming your files are in wav format\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        output_path = os.path.join(preprocessed_directory, filename)\n",
    "        \n",
    "        preprocess_audio(file_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCCs from an audio file\n",
    "def extract_mfcc(file_path, n_mfcc=13, n_fft=2048, hop_length=512):\n",
    "    audio, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfccs\n",
    "\n",
    "\n",
    "# Function to plot a heatmap for MFCCs\n",
    "def plot_mfcc_heatmap(mfccs, title):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_recordings\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Iterate over files in the directory and process each file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(directory):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# Construct full file path\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Directory containing preprocessed recordings\n",
    "directory = 'preprocessed_recordings'\n",
    "# Iterate over files in the directory and process each file\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Extract digit, speaker name, and index from the filename\n",
    "        parts = filename.split('_')\n",
    "        digit_label, speaker_name, index = parts[0], parts[1], parts[2].split('.')[0]\n",
    "        \n",
    "        # Extract MFCCs\n",
    "        mfccs = normalize_features(extract_mfcc(file_path))\n",
    "        \n",
    "        # Plot heatmap for the MFCCs\n",
    "        title = f\"MFCCs for {digit_label} by {speaker_name} (Index {index})\"\n",
    "        plot_mfcc_heatmap(mfccs, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files count: 2400, Test files count: 600\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def ensure_minimum_representation(files, test_size=0.2):\n",
    "    if len(files) == 1:\n",
    "        # If only one file, it goes into training; consider duplicating or using augmentation if needed for testing\n",
    "        return files, files\n",
    "    elif len(files) == 2:\n",
    "        # If two files, one goes into each set\n",
    "        return [files[0]], [files[1]]\n",
    "    else:\n",
    "        # More than two files, ensure at least one in each set and split the rest\n",
    "        train, test = train_test_split(files, test_size=test_size, random_state=42)\n",
    "        return train, test\n",
    "\n",
    "input_dir = 'preprocessed_recordings'\n",
    "speaker_digit_files = {}\n",
    "\n",
    "# Organize files by speaker and digit\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        digit, speaker, _ = filename.rsplit('_', 2)\n",
    "        speaker_digit_key = f\"{speaker}_{digit}\"\n",
    "        if speaker_digit_key not in speaker_digit_files:\n",
    "            speaker_digit_files[speaker_digit_key] = []\n",
    "        speaker_digit_files[speaker_digit_key].append(filename)\n",
    "\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "# Ensure representation in both sets\n",
    "for files in speaker_digit_files.values():\n",
    "    train_subset, test_subset = ensure_minimum_representation(files)\n",
    "    train_files.extend(train_subset)\n",
    "    test_files.extend(test_subset)\n",
    "\n",
    "# Here train_files and test_files have at least one representation of each speaker-digit pair\n",
    "# You might need to adjust paths or handle the file saving/loading based on your setup\n",
    "\n",
    "print(f\"Train files count: {len(train_files)}, Test files count: {len(test_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMMLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files count: 2400, Test files count: 600\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'preprocessed_recordings'\n",
    "mfcc_dir = 'mfcc_normalized'  # Directory to save normalized and length-adjusted MFCCs\n",
    "if not os.path.exists(mfcc_dir):\n",
    "    os.makedirs(mfcc_dir)\n",
    "\n",
    "speaker_digit_files = {}\n",
    "\n",
    "# This part remains the same as your original code\n",
    "# Organizing files by speaker and digit\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        digit, speaker, _ = filename.rsplit('_', 2)\n",
    "        speaker_digit_key = f\"{speaker}_{digit}\"\n",
    "        if speaker_digit_key not in speaker_digit_files:\n",
    "            speaker_digit_files[speaker_digit_key] = []\n",
    "        speaker_digit_files[speaker_digit_key].append(filename)\n",
    "\n",
    "# Modifying this part to include MFCC extraction, normalization, and saving\n",
    "train_files, test_files = [], []\n",
    "\n",
    "for speaker_digit, files in speaker_digit_files.items():\n",
    "    train_subset, test_subset = ensure_minimum_representation(files)\n",
    "    \n",
    "    # Process train files\n",
    "    for train_file in train_subset:\n",
    "        mfccs = extract_mfcc(os.path.join(input_dir, train_file))\n",
    "        mfccs_normalized = normalize_features(mfccs)\n",
    "        np.save(os.path.join(mfcc_dir, train_file.replace('.wav', '.npy')), mfccs_normalized)\n",
    "        train_files.append(train_file.replace('.wav', '.npy'))\n",
    "    \n",
    "    # Process test files\n",
    "    for test_file in test_subset:\n",
    "        mfccs = extract_mfcc(os.path.join(input_dir, test_file))\n",
    "        mfccs_normalized = normalize_features(mfccs)\n",
    "        np.save(os.path.join(mfcc_dir, test_file.replace('.wav', '.npy')), mfccs_normalized)\n",
    "        test_files.append(test_file.replace('.wav', '.npy'))\n",
    "\n",
    "print(f\"Train files count: {len(train_files)}, Test files count: {len(test_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, num_hidden_states):\n",
    "        self.num_hidden_states = num_hidden_states\n",
    "        self.rand_state = np.random.RandomState(1)\n",
    "\n",
    "        self.initial_prob = self._normalize(self.rand_state.rand(self.num_hidden_states, 1))\n",
    "        self.transition_matrix = self._stochasticize(self.rand_state.rand(self.num_hidden_states, self.num_hidden_states))\n",
    "\n",
    "        self.mean = None\n",
    "        self.covariances = None\n",
    "        self.num_dimensions = None\n",
    "\n",
    "    def _forward(self, observation_matrix):\n",
    "        log_likelihood = 0.\n",
    "        T = observation_matrix.shape[1]\n",
    "        alpha = np.zeros(observation_matrix.shape)\n",
    "\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                ## TODO: Forward algorithm for the first time step\n",
    "            else:\n",
    "                ## TODO: Forward algorithm for the next time steps\n",
    "\n",
    "            alpha_sum = np.sum(alpha[:, t])\n",
    "            alpha[:, t] /= alpha_sum\n",
    "            log_likelihood += np.log(alpha_sum)\n",
    "\n",
    "        return log_likelihood, alpha\n",
    "\n",
    "    def _backward(self, observation_matrix):\n",
    "        T = observation_matrix.shape[1]\n",
    "        beta = np.zeros(observation_matrix.shape)\n",
    "\n",
    "        beta[:, -1] = np.ones(observation_matrix.shape[0])\n",
    "\n",
    "        for t in range(T - 1)[::-1]:\n",
    "            beta[:, t] = ## TODO: Backward algorithm for the time steps of the HMM\n",
    "            beta[:, t] /= np.sum(beta[:, t])\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def _state_likelihood(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = np.zeros((self.num_hidden_states, obs.shape[1]))\n",
    "\n",
    "        for s in range(self.num_hidden_states):\n",
    "            np.random.seed(self.rand_state.randint(1))\n",
    "            B[s, :] = ## TODO: Compute the likelihood of observations with multivariate normal pdf\n",
    "\n",
    "        return B\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x)\n",
    "\n",
    "    def _stochasticize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x, axis=1)\n",
    "\n",
    "    def _em_init(self, obs):\n",
    "        if self.num_dimensions is None:\n",
    "            self.num_dimensions = obs.shape[0]\n",
    "        if self.mean is None:\n",
    "            subset = self.rand_state.choice(np.arange(self.num_dimensions), size=self.num_hidden_states, replace=False)\n",
    "            self.mean = obs[:, subset]\n",
    "        if self.covariances is None:\n",
    "            self.covariances = np.zeros((self.num_dimensions, self.num_dimensions, self.num_hidden_states))\n",
    "            self.covariances += np.diag(np.diag(np.cov(obs)))[:, :, None]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _em_step(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        T = obs.shape[1]\n",
    "\n",
    "        B = ## TODO\n",
    "\n",
    "        log_likelihood, alpha = ## TODO\n",
    "        beta = ## TODO\n",
    "\n",
    "        xi_sum = np.zeros((self.num_hidden_states, self.num_hidden_states))\n",
    "        gamma = np.zeros((self.num_hidden_states, T))\n",
    "\n",
    "        for t in range(T - 1):\n",
    "            partial_sum = ## TODO\n",
    "            xi_sum += self._normalize(partial_sum)\n",
    "            partial_g = ## TODO\n",
    "            gamma[:, t] = self._normalize(partial_g)\n",
    "        partial_g = ## TODO\n",
    "        gamma[:, -1] = self._normalize(partial_g)\n",
    "\n",
    "        expected_prior = ## TODO\n",
    "        expected_transition = self._stochasticize(## TODO)\n",
    "\n",
    "        expected_covariances = np.zeros((self.num_dimensions, self.num_dimensions, self.num_hidden_states))\n",
    "        expected_covariances += .01 * np.eye(self.num_dimensions)[:, :, None]\n",
    "\n",
    "        gamma_state_sum = np.sum(gamma, axis=1)\n",
    "        gamma_state_sum = gamma_state_sum + (gamma_state_sum == 0)\n",
    "\n",
    "        expected_mean = np.zeros((self.num_dimensions, self.num_hidden_states))\n",
    "        for s in range(self.num_hidden_states):\n",
    "            gamma_obs = obs * gamma[s, :]\n",
    "            expected_mean[:, s] = np.sum(gamma_obs, axis=1) / gamma_state_sum[s]\n",
    "\n",
    "        self.initial_prob = expected_prior\n",
    "        self.mean = expected_mean\n",
    "        self.covariances = expected_covariances\n",
    "        self.transition_matrix = expected_transition\n",
    "\n",
    "        return log_likelihood\n",
    "\n",
    "    def train(self, obs, num_iterations=1):\n",
    "        for i in range(num_iterations):\n",
    "            self._em_init(obs)\n",
    "            self._em_step(obs)\n",
    "        return self\n",
    "\n",
    "    def score(self, obs):\n",
    "        B = self._state_likelihood(obs)\n",
    "        log_likelihood, _ = self._forward(B)\n",
    "        return log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " hmm_models = []\n",
    "\n",
    "## TODO \n",
    "# Iterate through each unique genre in the training data\n",
    "# extract features from the audio files, and train a HMM for\n",
    "# each genre, storing the trained models in the hmm_models list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# In this section, iterate through the audio files, extract\n",
    "# features, and use the trained HMMs to predict the genre\n",
    "# for each audio file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
